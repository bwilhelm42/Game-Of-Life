Creating a visual display
    Frameworks? SDL seems good, but maybe overkill. Netbpm is a possible option, but maybe too much work to print simple images
        As of now, planning on using SDL
    display every frame to show movement?
    display just the fram of repetition? <-- This one is more inline with monitoring performance advancements

Evaluating oscilating board states
    use a constant max cycle number <-- straight forward and logical, but breaks badly if the cycle exceeds this value
    need a fixed board size in the event of a shape that infinitely generates in order to force some kind of 'steady' states


Ideas for how the program should execute:

Primary:
    1) Display an interactable grid where the user can select squares to give a starting state for the game
    2) Determine runtime mode (fast or slow)
        fast mode: execute the code as quickly as possible, this is the main point so we can benchmark performance
        slow mode: execute the code with delays between each frame so the user can track how each scene is evolving
    3) Display perceived "stead state" with total runtime



Using These 3 public variables, I can make the block and thread count flexible for different GPUs:

int cudaDeviceProp::multiProcessorCount [inherited]
int cudaDeviceProp::maxBlocksPerMultiProcessor [inherited]
int cudaDeviceProp::maxThreadsPerBlock [inherited]


careful with if statements as to not cause "warp divergence" since each warp is meant to execute the same set of 
instructions, in the situation where an if statement causes 1+ threads in a warp to start completing a different
opteration, performance can suffer. If one warp has multiple different opterations to perform by different threads
it will end up running them sequentially rather than concurrently.

Right now largest memory suck is the initial HtoD memory transfer because it it using pageable data instead of pinned data. The issue is that since the memory is being
allocated in a seperate file that has a ".c" extension, I am unable to use cudaMallocHost() to allocate is as pinned data. Currently the only solution I can come up with
is to turn the initializer file into a ".cu" cuda file. While there is nothing inherently wrong with doing this I don't like the idea of making an entire file a cuda file
just for one line of memory allocation.

WHAT IS MY REASONING FOR USING AS FEW CUDA FILES AS POSSIBLE???
I do this to maintain clarity of code. I believe that with many file, if I'm able to only utilize files with a .cu extension on fragments of code that are running the kernels
it is much easier to pick apart the code and pinpoint where cuda is being used. As mentioned above, I may make a slight exception to this rule so I can create pinned memory for
a different function.